{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc7f8eb4-169c-4760-8bfe-6cc7242a2e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from collections import Counter\n",
    "import string\n",
    "from gensim.utils import tokenize\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d918105-c8a1-4ec9-9ef0-adc67a90a77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since ag_news couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /home/artemybombastic/.cache/huggingface/datasets/ag_news/default/0.0.0/eb185aade064a813bc0b7f42de02595523103ca4 (last modified on Tue Feb 25 16:23:48 2025).\n"
     ]
    }
   ],
   "source": [
    "newsdata=datasets.load_dataset('ag_news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "128214a6-9119-437c-93af-6d4038cce137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsdata['train']['label'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3f864510-167a-464d-a01a-42c5ca83f6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря 34\n"
     ]
    }
   ],
   "source": [
    "#Создаём словарь количества вхождений слов\n",
    "words=[]\n",
    "#str.maketrans('','',string.punctuation)-возврящяет словарь для замены\n",
    "#.translate ждёт словарь слов для замены\n",
    "for sent in newsdata['train']['text']:\n",
    "    proced_sent=sent.lower().translate(\n",
    "        str.maketrans('','',string.punctuation)\n",
    "    )\n",
    "    for word in tokenize(proced_seq):\n",
    "        words.append(word)\n",
    "        \n",
    "\n",
    "vocab = set(['<unk>','<bos>','<eos>','<pad>'])#Токеный неизвестногого слова, начала,конца последовательности и токен пустного пропуска для батчей\n",
    "\n",
    "\n",
    "treshold=30 #Порог для включения в словарь word2ind\n",
    "words=Counter(words)\n",
    "\n",
    "for word,cnt in words.items():\n",
    "    if cnt>treshold:\n",
    "        vocab.add(word)\n",
    "print(f'Размер словаря {len(vocab)}')\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "36c1112f-4c8c-4bfb-ac70-749e80a285c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2ind={i:char for char,i in enumerate(words)}\n",
    "ind2word={ca:i for char,i in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "148345ac-6308-4a0c-8377-dcd4931c2121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nets': 0,\n",
       " 'get': 1,\n",
       " 'carter': 2,\n",
       " 'from': 3,\n",
       " 'raptors': 4,\n",
       " 'indianapolis': 5,\n",
       " 'allstar': 6,\n",
       " 'vince': 7,\n",
       " 'was': 8,\n",
       " 'traded': 9,\n",
       " 'by': 10,\n",
       " 'the': 11,\n",
       " 'toronto': 12,\n",
       " 'to': 13,\n",
       " 'new': 14,\n",
       " 'jersey': 15,\n",
       " 'for': 16,\n",
       " 'alonzo': 17,\n",
       " 'mourning': 18,\n",
       " 'eric': 19,\n",
       " 'williams': 20,\n",
       " 'aaron': 21,\n",
       " 'and': 22,\n",
       " 'a': 23,\n",
       " 'pair': 24,\n",
       " 'of': 25,\n",
       " 'firstround': 26,\n",
       " 'draft': 27,\n",
       " 'picks': 28,\n",
       " 'yesterday': 29}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1bdffee1-869f-49ee-a970-ad679117c5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordDataset(Dataset):\n",
    "    def __init__(self,data):  \n",
    "        super(WordDataset,self).__init__()\n",
    "        self.data=data\n",
    "        self.unk='<unk>'\n",
    "        self.bos='<bos>'\n",
    "        self.eos='<eos>'\n",
    "        self.pad='<pad>'        \n",
    "    def __getitem__(self,idx:int):\n",
    "        #получаем оригинальные данные\n",
    "        sent=self.data['text'][idx]\n",
    "        label=self.data['label'][idx]\n",
    "        proc_sent=sent.lower().translate(\n",
    "            str.maketrans('','',string.punctuation)\n",
    "\n",
    "        )\n",
    "        #tokenized_sent=tokenize(proc_sent)\n",
    "        tokenized_sent=[self.bos]\n",
    "        tokenized_sent+=[\n",
    "            word2ind.get(word,self.unk) for word in tokenize(proc_sent)\n",
    "        ]\n",
    "        tokenized_sent+=[self.eos]\n",
    "\n",
    "        sample={\n",
    "            'text':tokenized_sent,\n",
    "            'label':label\n",
    "        }\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b5fbbc5-90f9-4a1e-bdff-0bbbdfa57a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_dataset=WordDataset(newsdata['train'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2abe468b-ee5c-49f8-99bf-67aa15007f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'nets',\n",
       " 1: 'get',\n",
       " 2: 'carter',\n",
       " 3: 'from',\n",
       " 4: 'raptors',\n",
       " 5: 'indianapolis',\n",
       " 6: 'allstar',\n",
       " 7: 'vince',\n",
       " 8: 'was',\n",
       " 9: 'traded',\n",
       " 10: 'by',\n",
       " 11: 'the',\n",
       " 12: 'toronto',\n",
       " 13: 'to',\n",
       " 14: 'new',\n",
       " 15: 'jersey',\n",
       " 16: 'for',\n",
       " 17: 'alonzo',\n",
       " 18: 'mourning',\n",
       " 19: 'eric',\n",
       " 20: 'williams',\n",
       " 21: 'aaron',\n",
       " 22: 'and',\n",
       " 23: 'a',\n",
       " 24: 'pair',\n",
       " 25: 'of',\n",
       " 26: 'firstround',\n",
       " 27: 'draft',\n",
       " 28: 'picks',\n",
       " 29: 'yesterday'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d9708479-7bfb-4a48-bda8-f01dd9f5e47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wall\n",
      "st\n",
      "bears\n",
      "claw\n",
      "back\n",
      "into\n",
      "the\n",
      "black\n",
      "reuters\n",
      "reuters\n",
      "short\n",
      "sellers\n",
      "wall\n",
      "street\n",
      "s\n",
      "dwindling\n",
      "band\n",
      "of\n",
      "ultra\n",
      "cynics\n",
      "are\n",
      "seeing\n",
      "green\n",
      "again\n"
     ]
    }
   ],
   "source": [
    "for word in tokenize(newsdata['train']['text'][0]):\n",
    "    print(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33ba7076-4c1a-4409-a43d-7edc4dac3a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=tokenize(newsdata['train']['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8ba5db70-55d7-4c2e-a9af-53a33e56643c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73b1f01e-c7e7-4375-a3b8-c3ee157ece86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['<bos>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<eos>'],\n",
       " 'label': 2}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_dataset[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c189aa7a-82f3-4f45-870f-6d2bad039b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
